{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the next text, perform the following actions\n",
    "text = \"The president of the U.S.A., Donald Trump, is 1.9m high and 78 years old. Forbes Magazine has assessed his wealth, currently estimating it at $5.5 billion as of mid-February 2025.\"\n",
    "\n",
    "# (1 point) 1 - Use NLTK to split the sentences \n",
    "\n",
    "# (2 points) 2 - Convert with regex the acronym U.S.A. to USA, the number 1.9m to 190 centimeters or any other number of a height like that (e.g. 1.75m to 175 centimeters), and \"$5.5 billion\" to five point five billion. \n",
    "\n",
    "# (1 point) 3 - Convert to lowercase except the proper nouns that must keep the original case. For the multiword proper names convert them to an unique word joining the two word with underscoere (Juan Fern치ndez -> Juan_Fern치ndez).\n",
    "\n",
    "# (1 point) 4 - Tokenize the text (use the tool you prefer). \n",
    "\n",
    "# (1 point) 5 - Remove the stopwords (use the tool you prefer). \n",
    "\n",
    "# (1 point) 6 - Create bigrams with pure python.\n",
    "\n",
    "# (2 point) 7 - Create a language model that predict the next word using bigrams. Please explain in the code how you made the calculations.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "from num2words import num2words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1 point) 1 - Use NLTK to split the sentences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The president of the U.S.A., Donald Trump, is 1.9m high and 78 years old.', 'Forbes Magazine has assessed his wealth, currently estimating it at $5.5 billion as of mid-February 2025.']\n"
     ]
    }
   ],
   "source": [
    "sentences = nltk.sent_tokenize(text)\n",
    "\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2 points) 2 - Convert with regex the acronym U.S.A. to USA, the number 1.9m to 190 centimeters or any other number of a height like that (e.g. 1.75m to 175 centimeters), and \"$5.5 billion\" to five point five billion. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The president of the USA, Donald Trump, is 190 centimeters high and 78 years old. Forbes Magazine has assessed his wealth, currently estimating it at five point five billion as of mid-February 2025.\n"
     ]
    }
   ],
   "source": [
    "text = re.sub(r'U\\.S\\.A\\.', 'USA', text)\n",
    "\n",
    "text = re.sub(r'(\\d+\\.\\d+)m', lambda x: f\"{int(float(x.group(1)) * 100)} centimeters\", text)\n",
    "\n",
    "def decimal_to_words(match):\n",
    "    number = match.group(1)  # Extract the decimal number (e.g., \"5.5\")\n",
    "    integer_part, decimal_part = number.split(\".\")  # Split into whole and decimal parts\n",
    "    return f\"{num2words(int(integer_part))} point {num2words(int(decimal_part))} billion\"\n",
    "\n",
    "text = re.sub(r'\\$(\\d+\\.\\d+)\\sbillion', decimal_to_words, text)\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1 point) 3 - Convert to lowercase except the proper nouns that must keep the original case. For the multiword proper names convert them to an unique word joining the two word with underscoere (Juan Fern치ndez -> Juan_Fern치ndez).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the president of the USA, Donald_Trump, is 190 centimeters high and 78 years old. Forbes_Magazine has assessed his wealth, currently estimating it at five point five billion as of mid-February 2025.\n"
     ]
    }
   ],
   "source": [
    "def process_text(text):\n",
    "    proper_nouns = [\"USA\", \"Donald Trump\", \"Forbes Magazine\", \"mid-February\"]\n",
    "    \n",
    "    for proper in proper_nouns:\n",
    "        text = re.sub(r'\\b' + re.escape(proper) + r'\\b', proper.replace(\" \", \"_\"), text)\n",
    "\n",
    "    words = text.split()\n",
    "    processed_words = []\n",
    "\n",
    "    for word in words:\n",
    "        if \"_\" in word or word.isupper() or word == \"mid-February\":  \n",
    "            processed_words.append(word)\n",
    "        else:\n",
    "            processed_words.append(word.casefold())\n",
    "\n",
    "    return \" \".join(processed_words)\n",
    "\n",
    "processed_text = process_text(text)\n",
    "print(processed_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1 point) 4 - Tokenize the text (use the tool you prefer). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the president of the USA, Donald_Trump, is 190 centimeters high and 78 years old.', 'Forbes_Magazine has assessed his wealth, currently estimating it at five point five billion as of mid-February 2025.']\n",
      "['the', 'president', 'of', 'the', 'USA', ',', 'Donald_Trump', ',', 'is', '190', 'centimeters', 'high', 'and', '78', 'years', 'old', '.', 'Forbes_Magazine', 'has', 'assessed', 'his', 'wealth', ',', 'currently', 'estimating', 'it', 'at', 'five', 'point', 'five', 'billion', 'as', 'of', 'mid-February', '2025', '.']\n"
     ]
    }
   ],
   "source": [
    "processed_words = nltk.word_tokenize(processed_text)\n",
    "processed_sentences = nltk.sent_tokenize(processed_text)\n",
    "print(processed_sentences)\n",
    "print(processed_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1 point) 5 - Remove the stopwords (use the tool you prefer). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1 point) 6 - Create bigrams with pure python.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2 point) 7 - Create a language model that predict the next word using bigrams. Please explain in the code how you made the calculations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
